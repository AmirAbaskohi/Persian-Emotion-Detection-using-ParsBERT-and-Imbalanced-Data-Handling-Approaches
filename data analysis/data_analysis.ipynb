{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1efab77-2fc0-457b-a705-3e8f3f4c18ea",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0063c4-714e-4ada-96f2-27875601da81",
   "metadata": {},
   "source": [
    "## Reading the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80215a-0ca2-493d-9a59-1071992b8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../main dataset/dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb04d4-c1bd-4b29-bee6-723dc8e6fbad",
   "metadata": {},
   "source": [
    "## Checking None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16979dd8-10ee-4468-9be5-19e0b309ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6444bba-be56-40c8-9929-f22a45819ed2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0adee4d-78f9-4163-84ba-eaf145fa6895",
   "metadata": {},
   "source": [
    "### Tweet length analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b90edf-a613-4d06-b923-eda4abe73969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hazm\n",
    "\n",
    "df['tweet_len_by_words'] = df['text'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
    "df['tweet_len_by_sents'] = df['text'].apply(lambda t: len(hazm.sent_tokenize(t)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118a192-045f-4c8c-b5dd-56655974a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calFreq(samples):\n",
    "    result = {}\n",
    "    for sample in samples:\n",
    "        if result.get(sample):\n",
    "            result[sample] += 1\n",
    "        else:\n",
    "            result[sample] = 1\n",
    "    return result\n",
    "\n",
    "tweet_len_by_words_freq = calFreq(df[\"tweet_len_by_words\"].to_list())\n",
    "tweet_len_by_sents_freq = calFreq(df[\"tweet_len_by_sents\"].to_list())\n",
    "\n",
    "tweet_len_by_words_freq = dict(sorted(tweet_len_by_words_freq.items()))\n",
    "tweet_len_by_sents_freq = dict(sorted(tweet_len_by_sents_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcc8a4-2f46-4b96-8381-b8645db667d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Tweet length by words\")\n",
    "plt.xlabel(\"Tweet length\")\n",
    "plt.ylabel(\"Tweet legth frquency\")\n",
    "plt.plot(tweet_len_by_words_freq.keys(), list(tweet_len_by_words_freq.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e50cc-2a2c-485d-9be1-f6993d996914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Tweet length by sentences\")\n",
    "plt.xlabel(\"Tweet length\")\n",
    "plt.ylabel(\"Tweet legth frquency\")\n",
    "plt.plot(tweet_len_by_sents_freq.keys(), list(tweet_len_by_sents_freq.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab087f0-c3b3-4ad9-af2b-8fce7217680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_len = [\n",
    "    df[\"tweet_len_by_words\"].min(),\n",
    "    df[\"tweet_len_by_words\"].max(),\n",
    "    df[\"tweet_len_by_sents\"].min(),\n",
    "    df[\"tweet_len_by_sents\"].max()\n",
    "]\n",
    "print(f'Min length by word: {min_max_len[0]} \\tMax length by word: {min_max_len[1]}')\n",
    "print(f'Min length by sent: {min_max_len[2]} \\tMax length by sent: {min_max_len[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579b8a4-6ebd-47f7-b045-63b889f2495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGreaterLessThan(data, less_than=100.0, greater_than=0.0, col='tweet_len_by_words'):\n",
    "    data_length = data[col].values\n",
    "    data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
    "    data_glt_rate = (data_glt / len(data_length)) * 100\n",
    "    print(f'Texts with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b6f5a-0474-471d-b220-c8725eb98bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGreaterLessThan(df, 2, 0, 'tweet_len_by_sents')\n",
    "dataGreaterLessThan(df, 3, 0, 'tweet_len_by_sents')\n",
    "dataGreaterLessThan(df, 5, 0, 'tweet_len_by_sents')\n",
    "dataGreaterLessThan(df, 93, 3, 'tweet_len_by_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2b89f-612f-4df1-9b51-b5973626099e",
   "metadata": {},
   "source": [
    "## Idea based on these length results\n",
    "We know that length are very important in the `Natural Language Processing`, as the models are highly dependant on the length of the sentences, especially `vectorzers` and `tokenizers`.\n",
    "\n",
    "In the future, we can get the subset of data in a way that very low and very high sentences be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b52d6-ce05-4241-b8db-aa2a3deecb0a",
   "metadata": {},
   "source": [
    "## Checking target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d252a-6f19-47c0-bb98-fccbda27ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Sadness').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213734db-b452-4b25-9d1f-de6903fe8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "targetCols = ['Sadness', 'Wonder', 'Hatred', 'Happiness', 'Fear', 'Anger']\n",
    "\n",
    "for targetCol in targetCols:\n",
    "    opacity = 0.4\n",
    "    bar_width = 0.35\n",
    "    plt.xlabel(f'{targetCol} rate')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {targetCol} rate within tweets')\n",
    "    groupby_rate = df.groupby(targetCol)\n",
    "    df[targetCol].value_counts().sort_values().plot(kind = 'barh')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
